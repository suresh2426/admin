***Creating synthetic dataset with faker***
pip install faker
import faker
fake = faker.Faker()
for _ in range(5):
    print("Name: " ,fake.name())
    print("Address: ",fake.address())
    print("DOB: ", fake.date_of_birth())
    print("City: ", fake.city())
    print("Country: ", fake.country())
    print("Email: " , fake.email())
    print("Phone: ", fake.phone_number())
    print("Review: " , fake.text())
    print("-----------------")

fake = faker.Faker("gu_IN")
# hi_IN : for Hindi
for _ in range(5):
    print("Name: " ,fake.name())
    print("Address: ",fake.address())
    print("DOB: ", fake.date_of_birth())
    print("City: ", fake.city())
    print("Country: ", fake.country())
    print("Email: " , fake.email())
    print("Phone: ", fake.phone_number())
    print("Review: " , fake.text())
    print("-----------------")

import pandas as pd
import random
fake = faker.Faker()
data_dict= []
genders = ['Male', 'Female']
courses = ['MBA','MCA']
for _ in range(100):
  data_dict.append({"Name: ": fake.name(), "Address: " : fake.address(), "Gender: " : random.choice(genders),
                    "City: ": fake.city(), "Country: ": fake.country(),
                    "Review: ": fake.text(), "Courses: ": random.choice(courses)})
df = pd.DataFrame(data_dict)
# print(df)
df.to_csv("Data.csv", index=False)
fp = pd.read_csv("Data.csv")
fp

import faker
import faker_commerce
import random
import asyncio
import pandas as pd
faker = faker.Faker()
faker.add_provider(faker_commerce.Provider)
positive_words = ["versatile","excellent","worthy","great","good","friendly","efficient","durable","latest"]
negative_words = ["worst","bad","pathetic","trash","poor","disappointing","useless","broken","expensive"]
positive_phrases = [
    "Excellent quality",
    "Fast shipping",
    "Great value for money",
    "User-friendly website",
    "Responsive customer service",
    "Easy checkout process",
    "Wide product selection",
    "Accurate product descriptions",
    "Secure payment options",
    "Hassle-free returns"
]
negative_phrases = [
    "Poor product quality",
    "Late delivery",
    "Misleading product images",
    "Difficult return policy",
    "Unresponsive customer support",
    "Hidden shipping fees",
    "Complicated checkout process",
    "Out of stock frequently",
    "Incorrect product descriptions",
    "Payment system errors"
]
data = []
def generate_review(prod, type="positive"):  # removed undefined "product" default
    if type == "positive":
        return f"{prod} is {random.choice(positive_words)} and {random.choice(positive_phrases)}"
    else:
        return f"{prod} is {random.choice(negative_words)} and {random.choice(negative_phrases)}"
async def generate_positive_data():
    for _ in range(5):
        product = faker.ecommerce_name()
        data.append([product, generate_review(product, "positive"), "positive"])
        await asyncio.sleep(2)
async def generate_negative_data():
    for _ in range(5):
        product = faker.ecommerce_name()
        data.append([product, generate_review(product, "negative"), "negative"])
        await asyncio.sleep(1)
await asyncio.gather(generate_positive_data(), generate_negative_data())
product_df = pd.DataFrame(data, columns=["Product", "Review", "Sentiment"])
product_df

import faker
import faker_commerce
import random
import asyncio
import pandas as pd
faker = faker.Faker()
faker.add_provider(faker_commerce.Provider)
product_names_marathi = [
    "рд╕реНрдорд╛рд░реНрдЯрдлреЛрди", "рд▓реЕрдкрдЯреЙрдк", "рдЯреАрд╡реНрд╣реА", "рдлреНрд░рд┐рдЬ", "рд╡реЙрд╢рд┐рдВрдЧ рдорд╢реАрди",
    "рдХреЕрдореЗрд░рд╛", "рд╣реЗрдбрдлреЛрди", "рд╕реНрдкреАрдХрд░реНрд╕", "рдШрдбреНрдпрд╛рд│", "рд╕рд╛рдпрдХрд▓",
    "рдПрдЕрд░ рдХрдВрдбрд┐рд╢рдирд░", "рдорд┐рдХреНрд╕рд░ рдЧреНрд░рд╛рдЗрдВрдбрд░", "рдЗрд▓реЗрдХреНрдЯреНрд░рд┐рдХ рдХреЗрддрд▓реА", "рдЯреЕрдмрд▓реЗрдЯ",
    "рдкреНрд░рд┐рдВрдЯрд░", "рдХреВрд▓рд░", "рдмреБрдХ", "рдмреЕрдЧ", "рд╢реВрдЬ", "рдЯреА-рд╢рд░реНрдЯ"
]
positive_words_marathi = [
    "рдЙрддреНрдХреГрд╖реНрдЯ ЁЯСН", "рдЬрд▓рдж ЁЯЪА", "рд╡рд┐рд╢реНрд╡рд╛рд╕рд╛рд░реНрд╣ тЬЕ", "рдЯрд┐рдХрд╛рдК ЁЯТк", "рд╕реБрдВрджрд░ ЁЯМЯ",
    "рдЖрд░рд╛рдорджрд╛рдпрдХ ЁЯЫЛя╕П", "рдЙрдкрдпреБрдХреНрдд ЁЯОп", "рдкрд░рд╡рдбрдгрд╛рд░реЗ ЁЯТ░", "рд╕реЛрдкрдВ ЁЯЦ▒я╕П", "рдЪрд╛рдВрдЧрд▓рд╛ ЁЯПЕ",
    "рдЖрдХрд░реНрд╖рдХ тЬи", "рд╕рд╢рдХреНрдд ЁЯТе", "рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп ЁЯФТ", "рдЧреБрдгрд╡рддреНрддрд╛рдкреВрд░реНрдг ЁЯПЖ", "рддрдпрд╛рд░рджрд╛рд░ ЁЯФз",
    "рддрдЬреНрдЮрд╛рдЪрд╛ ЁЯза", "рд╕реБрд▓рдн ЁЯФС", "рдирд╡реАрдирддрдо ЁЯЖХ", "рдлрд╛рдпрджреНрдпрд╛рдЪреЗ ЁЯТб", "рдкреНрд░рднрд╛рд╡реА ЁЯФе"
]
positive_phrases_marathi = [
    "рдЬрд▓рдж рд╕реЗрд╡рд╛ тЪб", "рд╡рд╛рдкрд░рдгреНрдпрд╛рд╕ рд╕реЛрдкрд╛ ЁЯШК", "рд╡рд┐рд╕реНрддреГрдд рдкрд░реНрдпрд╛рдп ЁЯУж", "рд╕реБрд░рдХреНрд╖рд┐рдд рдкреЗрдореЗрдВрдЯ ЁЯФТ", "рдкрд░рддрд╛рд╡рд╛ рд╕реЛрдкрд╛ ЁЯФД",
    "рдЧреНрд░рд╛рд╣рдХрд╛рдВрд╕рд╛рдареА рдореИрддреНрд░реАрдкреВрд░реНрдг ЁЯдЭ", "рдирд╡реАрдирддрдо рдореЙрдбреЗрд▓ ЁЯЖХ", "рдЙрдЪреНрдЪ рджрд░реНрдЬрд╛рдЪрд╛ тЬи", "рд╕рдорд╛рдзрд╛рдирдХрд╛рд░рдХ ЁЯСНЁЯП╗", "рдЙрддреНрддрдо рджрд░реНрдЬрд╛рдЪрд╛ рдЕрдиреБрднрд╡ ЁЯМЯ",
    "рдпреЛрдЧреНрдп рдХрд┐рдВрдордд ЁЯТ░", "рддрдВрддреНрд░рдЬреНрдЮрд╛рдирд╛рдд рдЖрдШрд╛рдбреАрд╡рд░ ЁЯЦея╕П", "рджрд░реНрдЬреЗрджрд╛рд░ рдмрд╛рдВрдзрдХрд╛рдо ЁЯПЧя╕П", "рдкрд░рдлреЗрдХреНрдЯ рдлрд┐рдЯрд┐рдВрдЧ ЁЯСМ", "рдЬрд▓рдж рд╡рд┐рддрд░рдг ЁЯЪЪ",
    "рдЙрдЪреНрдЪ рдХрд╛рд░реНрдпрдХреНрд╖рдорддрд╛ тЪЩя╕П", "рд╕рдВрдкреВрд░реНрдг рд╣рдореА ЁЯЫбя╕П", "рд╕рд╣рдЬ рд╡рд╛рдкрд░рдХрд░реНрддрд╛ рдЗрдВрдЯрд░рдлреЗрд╕ ЁЯЦ▒я╕П", "рдЕрддреНрдпрд╛рдзреБрдирд┐рдХ рдбрд┐рдЭрд╛рдЗрди ЁЯОи", "рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рдмреНрд░рдБрдб ЁЯМР"
]
negative_words_marathi = [
    "рдЦрд░рд╛рдм ЁЯШЮ", "рдЙрд╢реАрд░ тП░", "рдлрд╕рд╡рдгреВрдХ тЭМ", "рддреБрдЯрд▓реЗрд▓реЗ ЁЯФз", "рддреНрд░рд╛рд╕рджрд╛рдпрдХ ЁЯШб",
    "рдорд╣рд╛рдЧрдбреЗ ЁЯТ╕", "рдЕрд╡рдШрдб ЁЯШХ", "рдирд┐рдХреГрд╖реНрдЯ тЪая╕П", "рдЪреБрдХреАрдЪреЗ ЁЯУЙ", "рдирд┐рд░рд╛рд╢рд╛ ЁЯУ╡",
    "рдЕрдХрд╛рд░реНрдпрдХреНрд╖рдо ЁЯЫС", "рдзреЛрдХрд╛рджрд╛рдпрдХ тШая╕П", "рджреБрд░реНрдмрд▓ ЁЯТФ", "рдлреЗрд▓ тЭМ", "рдЕрдпреЛрдЧреНрдп тЭЧ",
    "рдЕрд╕рдВрддреБрд╖реНрдЯ ЁЯШа", "рдЕрд╡рд┐рд╢реНрд╡рд╕рдиреАрдп ЁЯФУ", "рдХрдореА рджрд░реНрдЬрд╛рдЪрд╛ ЁЯСО", "рд╡рд┐рдХреГрдд ЁЯФД", "рдЕрд╕рд╛рдзрд╛рд░рдг ЁЯРв"
]
negative_phrases_marathi = [
    "рдкрд░рддрд╛рд╡рд╛ рдХрдареАрдг ЁЯФТ", "рд╕реНрдЯреЙрдХ рд╕рдВрдкрд▓реЗрд▓реЗ ЁЯЫС", "рдЫрд╛рдпрд╛рдЪрд┐рддреНрд░ рдЪреБрдХреАрдЪреЗ ЁЯУ╕тЭМ", "рдЪреБрдХреАрдЪрд╛ рдЖрдХрд╛рд░ ЁЯУПтЭМ", "рд╣рд╛рдпрд╢рд┐рдкрд┐рдВрдЧ рд╢реБрд▓реНрдХ ЁЯТ░тЪая╕П",
    "рд╡рд┐рд╕реНрдХрд│реАрдд рдкреНрд░рдХреНрд░рд┐рдпрд╛ ЁЯФДтЭМ", "рдЯреНрд░реЕрдХрд┐рдВрдЧ рдЙрдкрд▓рдмреНрдз рдирд╛рд╣реА ЁЯХ╡я╕ПтАНтЩВя╕ПтЭМ", "рдЖрд╡рд╛рдЬ рдЦреВрдк рдХрдореА ЁЯФЗ", "рдЧреБрдгрд╡рддреНрддрд╛ рдирд┐рдХреГрд╖реНрдЯ ЁЯСО", "рдЕрдпреЛрдЧреНрдп рдлрд┐рдЯрд┐рдВрдЧ ЁЯСХ",
    "рдЧреНрд░рд╛рд╣рдХ рд╕реЗрд╡рд╛ рдЕрдкреБрд░реА ЁЯУ╡", "рдбрд┐рд▓рд┐рд╡реНрд╣рд░реА рдЙрд╢реАрд░ тП│", "рдкреНрд░реЙрдбрдХреНрдЯ рдЦрд░рд╛рдм рдЭрд╛рд▓рд╛ ЁЯФз", "рдХрдореА рдЯрд┐рдХрд╛рдКрдкрдгрд╛ ЁЯХ░я╕П", "рдлрд╕рд╡рдгреВрдХ рдХрд░рдгрд╛рд░рд╛ рд╡рд░реНрдгрди ЁЯУДтЭМ",
    "рд╡рд╛рдкрд░рдгреНрдпрд╛рд╕ рдЕрд╡рдШрдб ЁЯзй", "рдХрдореА рдХрд╛рд░реНрдпрдХреНрд╖рдо тЪая╕П", "рд╡рд╛рдЯрдкрд╛рдЪреА рд╕рдорд╕реНрдпрд╛ ЁЯЪл", "рдЦреВрдк рдХрд┐рдВрдордд ЁЯТ╕", "рд╡рд┐рдХреНрд░реАрдирдВрддрд░ рд╕реЗрд╡рд╛ рдирд╛рд╣реА ЁЯЫС"
]
data = []
def generate_review(prod, type="positive"):  # removed undefined "product" default
    # product = faker.ecommerce_name()
    if type == "positive":
        return f"{prod} is {random.choice(positive_words_marathi)} and {random.choice(positive_phrases_marathi)}"
    else:
        return f"{prod} is {random.choice(negative_words_marathi)} and {random.choice(negative_phrases_marathi)}"
# for _ in range(100):
#   product = random.choice(product_names_marathi)
#   data.append([product, generate_review(product,"positive"),"positive"])
# for _ in range(100):
#   product = random.choice(product_names_marathi)
#   data.append([product, generate_review(product, "negative"),"negative"])
async def generate_positive_data():
    for _ in range(50):
        product = random.choice(product_names_marathi)
        data.append([product, generate_review(product, "positive"), "positive"])
        await asyncio.sleep(2)
async def generate_negative_data():
    for _ in range(50):
        product = random.choice(product_names_marathi)
        data.append([product, generate_review(product, "negative"), "negative"])
        await asyncio.sleep(1)
await asyncio.gather(generate_positive_data(), generate_negative_data())
product_df = pd.DataFrame(data, columns=["Product", "Review", "Sentiment"])
product_df.to_csv("ProductData.csv", index=False)
fp2 = pd.read_csv("ProductData.csv")
fp2

***actual webscrape***
from bs4 import BeautifulSoup
import requests
import pandas as pd
url = "https://en.wikipedia.org/wiki/List_of_state_and_union_territory_capitals_in_India"
header = {
    "User-Agent" : "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36",
}
response = requests.get(url, headers=header)
response
html_content = BeautifulSoup(response.content, "html.parser")
html_content
table = html_content.find_all("table", {"class":"wikitable sortable"})
table
df = pd.read_html(str(table))
df[0]

***speech to text***
!pip install SpeechRecognition
!pip install pydub

from pydub import AudioSegment
import speech_recognition as sr
import os
from pickle import TRUE
from genericpath import exists
recogniser = sr.Recognizer()
# source = AudioSegment.from_mp3("/content/talking-46836.mp3")
source = AudioSegment.from_wav("/content/harvard.wav")
# source = AudioSegment.from_mp3("/content/marathi.mp3")
# source.export("/content/talking-46836.wav", format="wav")
with sr.AudioFile("/content/harvard.wav") as source:
  audio_source = recogniser.record(source)
  print("recognising......")
  try:
    # speech_text = recogniser.recognize_google(audio_source, language="mr-IN")
    speech_text = recogniser.recognize_google(audio_source)
    print("converted text: \n")
    print(speech_text)
  except:
    print("sorry could not recognize")

***video to text(English)***
from moviepy.editor import VideoFileClip
video = VideoFileClip("/content/Raman Ramachandran _ Careers .mp4")
video
audio_from_video = video.audio.write_audiofile("raman_ramchandran.mp3")
audio_from_video

from pydub import AudioSegment
import speech_recognition as sr
import os
recogniser = sr.Recognizer()
source = AudioSegment.from_mp3("/content/raman_ramchandran.mp3")
source.export("/content/raman_ramchandran.wav", format="wav")
with sr.AudioFile("/content/raman_ramchandran.wav") as source:
  audio_source = recogniser.record(source)
  print("recognizing........")
  try:
    speech_text = recogniser.recognize_google(audio_source)
    print("converted text: \n")
    print(speech_text)
  except:
    print("sorry could not recognize")

***video to text(Marathi)***
from moviepy.editor import VideoFileClip
video = VideoFileClip("/content/marathi_video.mp4")
video
audio_from_video = video.audio.write_audiofile("marathi_video.mp3")
audio_from_video

from pydub import AudioSegment
import speech_recognition as sr
import os
recogniser = sr.Recognizer()
source = AudioSegment.from_mp3("/content/marathi_video.mp3")
source.export("/content/marathi_video.wav", format="wav")
with sr.AudioFile("/content/marathi_video.wav") as source:
  audio_source = recogniser.record(source)
  print("recognizing........")
  try:
    speech_text = recogniser.recognize_google(audio_source, language="mr-IN")
    print("converted text: \n")
    print(speech_text)
  except:
    print("sorry could not recognize")

***Extract text from image***
!pip install pillow
!pip install pytesseract
!sudo apt install tesseract-ocr
!sudo apt install tesseract-dev
!sudo apt install tesseract-ocr-mar
!sudo apt install tesseract-ocr-hin
from PIL import Image
import pytesseract
image=Image.open("/content/hindi_poem.jpeg")
poem_text=pytesseract.image_to_string(image,lang="hin")
print(poem_text)

